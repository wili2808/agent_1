# ai_services.py (con prompts mejorados)
from langchain_ollama import OllamaLLM
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain
from config import Config
import logging
import re

logger = logging.getLogger(__name__)

class IAService:
    def __init__(self):
        try:
            self.llm = OllamaLLM(model=Config.LLM_MODEL, temperature=Config.LLM_TEMPERATURE)
            logger.info(f"Modelo LLM inicializado: {Config.LLM_MODEL}")
        except Exception as e:
            logger.error(f"Error inicializando LLM: {e}")
            # Fallback a un modelo simple si hay error
            self.llm = None
    
    def preprocesar_mensaje(self, mensaje):
        """
        Normaliza el mensaje eliminando ruido y prepar√°ndolo para el modelo.
        """
        mensaje = mensaje.lower().strip()  # Convertir a min√∫sculas y eliminar espacios
        mensaje = re.sub(r"[^a-zA-Z0-9√°√©√≠√≥√∫√±√º\s]", "", mensaje)  # Eliminar caracteres especiales
        return mensaje
    
    def clasificar_mensaje(self, mensaje):
        """
        Clasifica un mensaje en una de estas categor√≠as: facturar, consultar, ayuda, estado, otro.
        """
        if not mensaje or not self.llm:
            return "otro"
            
        try:
            # Prompt mejorado con ejemplos m√°s diversos
            prompt = ChatPromptTemplate.from_template(
                "Eres un asistente especializado en sistemas de facturaci√≥n que clasifica mensajes en una de estas categor√≠as:\n"
                "- facturar: mensajes que solicitan generar una factura o documento fiscal. Ejemplos: 'Facturar 2 licencias', 'Necesito factura de 3 monitores y 1 teclado', 'Generar factura para 5 servicios de consultor√≠a', 'Facturar los siguientes productos: 2 mesas, 4 sillas'.\n"
                "- consultar: mensajes que solicitan informaci√≥n sobre facturas existentes. Ejemplos: 'Consultar facturas de RFC ABC123456XYZ', 'Mostrar mis facturas del mes pasado', 'Ver facturas pendientes', 'Estado de mis facturas'.\n"
                "- ayuda: mensajes que piden instrucciones o informaci√≥n sobre el servicio. Ejemplos: '¬øC√≥mo funciona?', 'Opciones disponibles', 'Necesito ayuda', 'No s√© c√≥mo usar este servicio'.\n"
                "- estado: mensajes que preguntan espec√≠ficamente por el estado de una factura o tr√°mite. Ejemplos: '¬øEn qu√© estado est√° mi factura?', 'Estado de tr√°mite 12345', 'Seguimiento de factura'.\n"
                "- otro: mensajes que no pertenecen a ninguna categor√≠a anterior como saludos, agradecimientos o consultas no relacionadas.\n\n"
                "Analiza el siguiente mensaje y clasif√≠calo en una sola categor√≠a. Tu respuesta debe ser √∫nicamente la categor√≠a:\n\n"
                "Mensaje: {mensaje}\n"
                "Respuesta:"
            )
            chain = LLMChain(llm=self.llm, prompt=prompt)
            respuesta = chain.run(mensaje=mensaje).strip().lower()

            # Validar que la respuesta est√© en las categor√≠as esperadas
            categorias_validas = {"facturar", "consultar", "ayuda", "estado", "otro"}
            if respuesta not in categorias_validas:
                logger.warning(f"Respuesta inesperada del modelo: {respuesta}")
                return "otro"
            
            return respuesta
        except Exception as e:
            logger.error(f"Error clasificando mensaje: {e}")
            return "otro"
    
    def extraer_detalles_con_llm(self, mensaje):
        """
        Utiliza el LLM para extraer detalles m√°s complejos de un mensaje de facturaci√≥n
        cuando los patrones regulares no son suficientes
        """
        if not self.llm:
            return None
            
        try:
            prompt = ChatPromptTemplate.from_template(
                "Extrae la informaci√≥n de facturaci√≥n del siguiente mensaje. Debes identificar:\n"
                "1. El RFC del cliente\n"
                "2. Los productos mencionados y sus cantidades\n\n"
                "Devuelve tu respuesta en formato JSON con las siguientes propiedades:\n"
                "- rfc: El RFC mencionado (si existe)\n"
                "- productos: Lista de objetos, cada uno con 'nombre' y 'cantidad'\n\n"
                "Mensaje: {mensaje}\n\n"
                "JSON:"
            )
            chain = LLMChain(llm=self.llm, prompt=prompt)
            respuesta = chain.run(mensaje=mensaje).strip()
            
            # Intentar convertir la respuesta a JSON
            import json
            try:
                datos = json.loads(respuesta)
                return datos
            except json.JSONDecodeError:
                logger.warning(f"No se pudo decodificar la respuesta como JSON: {respuesta}")
                return None
                
        except Exception as e:
            logger.error(f"Error extrayendo detalles con LLM: {e}")
            return None
            
    def generar_respuesta_ayuda(self):
        """
        Genera un mensaje de ayuda para el usuario
        """
        return (
            "üîç *Asistente de Facturaci√≥n* üîç\n\n"
            "Puedes realizar las siguientes acciones:\n\n"
            "üìù *Generar una factura*\n"
            "Ejemplo: \"Facturar 2 licencias a RFC ABC123456XYZ\"\n"
            "Tambi√©n puedes facturar varios productos: \"Facturar 2 licencias y 3 servicios a RFC ABC123456XYZ\"\n\n"
            "üìä *Consultar facturas*\n"
            "Ejemplo: \"Consultar facturas de RFC ABC123456XYZ\"\n\n"
            "‚ùì *Ayuda*\n"
            "Escribe \"ayuda\" para ver este mensaje\n\n"
            "üì± *Estado de facturas*\n"
            "Ejemplo: \"Estado de mi factura para RFC ABC123456XYZ\""
        )